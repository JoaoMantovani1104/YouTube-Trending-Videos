import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import time
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ===========================================
# FUNÃ‡Ã•ES AUXILIARES
# ===========================================

def print_titulo(titulo):
    """Imprime um tÃ­tulo bonito"""
    print("\n" + "="*60)
    print(f"ğŸ”¹ {titulo}")
    print("="*60)

def print_secao(numero, titulo):
    """Imprime uma seÃ§Ã£o numerada"""
    print(f"\nğŸ“ {numero}. {titulo}")
    print("-" * 40)

def solicitar_modelo():
    """Solicita interativamente qual modelo usar"""
    print_titulo("CONFIGURAÃ‡ÃƒO INTERATIVA DO MODELO")
    print("\nğŸ¤– Modelos disponÃ­veis:")
    print("   1ï¸âƒ£  Ridge (RegressÃ£o Linear Regularizada)")
    print("   2ï¸âƒ£  RandomForest (Ãrvores AleatÃ³rias)")
    print("   3ï¸âƒ£  GradientBoosting (Gradient Boosting Regressor)")

    while True:
        escolha = input("\nğŸ‘‰ Escolha o modelo (1, 2 ou 3): ").strip()
        if escolha == '1':
            return 'Ridge'
        elif escolha == '2':
            return 'RandomForest'
        elif escolha == '3':
            return 'GradientBoosting'
        else:
            print("âŒ OpÃ§Ã£o invÃ¡lida! Digite 1, 2 ou 3.")

def solicitar_parametros_ridge():
    """Solicita parÃ¢metros para o modelo Ridge"""
    print("\nğŸ”§ Configurando Ridge:")
    print("   ğŸ“‹ Alpha: controla a regularizaÃ§Ã£o (quanto maior, mais simples o modelo)")
    print("   ğŸ’¡ SugestÃµes: 0.1 (pouca), 1.0 (mÃ©dia), 10.0 (alta regularizaÃ§Ã£o)")

    while True:
        try:
            alpha = float(input("\nğŸ‘‰ Digite o valor de alpha (ex: 10.0): "))
            if alpha > 0:
                return {'alpha': alpha}
            else:
                print("âŒ Alpha deve ser maior que zero!")
        except ValueError:
            print("âŒ Digite um nÃºmero vÃ¡lido!")

def solicitar_parametros_randomforest():
    """Solicita parÃ¢metros para o modelo RandomForest"""
    print("\nğŸ”§ Configurando RandomForest:")

    # N_estimators
    print("\nğŸŒ³ N_estimators: nÃºmero de Ã¡rvores na floresta")
    print("   ğŸ’¡ SugestÃµes: 50 (rÃ¡pido), 100 (padrÃ£o), 200 (mais preciso)")
    while True:
        try:
            n_est = int(input("ğŸ‘‰ Digite n_estimators (ex: 100): "))
            if n_est > 0:
                break
            else:
                print("âŒ Deve ser maior que zero!")
        except ValueError:
            print("âŒ Digite um nÃºmero inteiro!")

    # Max_depth
    print("\nğŸŒ² Max_depth: profundidade mÃ¡xima das Ã¡rvores")
    print("   ğŸ’¡ SugestÃµes: 5 (simples), 10 (padrÃ£o), None (sem limite)")
    while True:
        depth_input = input("ğŸ‘‰ Digite max_depth (ex: 10) ou 'None': ").strip()
        if depth_input.lower() == 'none':
            max_depth = None
            break
        else:
            try:
                max_depth = int(depth_input)
                if max_depth > 0:
                    break
                else:
                    print("âŒ Deve ser maior que zero!")
            except ValueError:
                print("âŒ Digite um nÃºmero inteiro ou 'None'!")

    return {'n_estimators': n_est, 'max_depth': max_depth, 'random_state': 42}

def solicitar_parametros_gradientboosting():
    """Solicita parÃ¢metros para o modelo GradientBoosting"""
    print("\nğŸ”§ Configurando GradientBoosting:")

    # N_estimators
    print("\nğŸŒ³ N_estimators: nÃºmero de Ã¡rvores de boosting")
    print("   ğŸ’¡ SugestÃµes: 50 (rÃ¡pido), 100 (padrÃ£o), 200 (mais preciso)")
    while True:
        try:
            n_est = int(input("ğŸ‘‰ Digite n_estimators (ex: 100): "))
            if n_est > 0:
                break
            else:
                print("âŒ Deve ser maior que zero!")
        except ValueError:
            print("âŒ Digite um nÃºmero inteiro!")

    # Learning rate
    print("\nğŸ“ˆ Learning_rate: taxa de aprendizado (shrinkage)")
    print("   ğŸ’¡ SugestÃµes: 0.01 (lento/preciso), 0.1 (padrÃ£o), 0.2 (rÃ¡pido)")
    while True:
        try:
            lr = float(input("ğŸ‘‰ Digite learning_rate (ex: 0.1): "))
            if 0 < lr <= 1:
                break
            else:
                print("âŒ Deve ser entre 0 e 1!")
        except ValueError:
            print("âŒ Digite um nÃºmero vÃ¡lido!")

    # Max_depth
    print("\nğŸŒ² Max_depth: profundidade mÃ¡xima das Ã¡rvores")
    print("   ğŸ’¡ SugestÃµes: 3 (simples), 6 (padrÃ£o), 10 (complexo)")
    while True:
        try:
            max_depth = int(input("ğŸ‘‰ Digite max_depth (ex: 6): "))
            if max_depth > 0:
                break
            else:
                print("âŒ Deve ser maior que zero!")
        except ValueError:
            print("âŒ Digite um nÃºmero inteiro!")

    return {'n_estimators': n_est, 'learning_rate': lr, 'max_depth': max_depth, 'random_state': 42}

def solicitar_configuracoes_gerais():
    """Solicita configuraÃ§Ãµes gerais do treinamento"""
    print("\nâš™ï¸  ConfiguraÃ§Ãµes Gerais:")

    # Tamanho do teste
    print("\nğŸ“Š Tamanho do conjunto de teste:")
    print("   ğŸ’¡ SugestÃµes: 0.2 (20%), 0.3 (30%)")
    while True:
        try:
            test_size = float(input("ğŸ‘‰ Digite a porcentagem para teste (ex: 0.2): "))
            if 0 < test_size < 1:
                break
            else:
                print("âŒ Deve ser entre 0 e 1!")
        except ValueError:
            print("âŒ Digite um nÃºmero vÃ¡lido!")

    # Random state
    print("\nğŸ² Random State (semente aleatÃ³ria para reprodutibilidade):")
    print("   ğŸ’¡ SugestÃµes: 42 (padrÃ£o), 123, qualquer nÃºmero")
    while True:
        try:
            random_state = int(input("ğŸ‘‰ Digite o random_state (ex: 42): "))
            break
        except ValueError:
            print("âŒ Digite um nÃºmero inteiro!")

    return test_size, random_state

def criar_nome_execucao(modelo, parametros, tamanho_teste, random_state):
    """Cria um nome Ãºnico para a execuÃ§Ã£o baseado nos parÃ¢metros"""
    # Mapeamento de abreviaÃ§Ãµes para parÃ¢metros
    abreviacoes = {
        'alpha': 'a',
        'n_estimators': 'ne',
        'max_depth': 'md',
        'learning_rate': 'lr'
    }

    # Construir string dos parÃ¢metros
    param_parts = []
    for chave, valor in parametros.items():
        if chave != 'random_state':  # NÃ£o incluir random_state nos parÃ¢metros
            abrev = abreviacoes.get(chave, chave[:2])
            if valor is None:
                param_parts.append(f"{abrev}None")
            else:
                # Remover pontos dos nÃºmeros decimais
                valor_str = str(valor).replace('.', '')
                param_parts.append(f"{abrev}{valor_str}")

    param_str = "_".join(param_parts)
    test_str = str(tamanho_teste).replace('.', '')

    # Timestamp para garantir unicidade
    timestamp = int(time.time()) % 10000  # Ãšltimos 4 dÃ­gitos do timestamp

    return f"execucao_{timestamp}_{param_str}_{test_str}test_{random_state}rs"

def contar_execucoes_modelo(modelo):
    """Conta quantas execuÃ§Ãµes jÃ¡ existem para um modelo"""
    pasta_modelo = modelo
    if os.path.exists(pasta_modelo):
        return len([d for d in os.listdir(pasta_modelo) if os.path.isdir(os.path.join(pasta_modelo, d))])
    return 0

def imprimir_info_dataset(df):
    """Imprime informaÃ§Ãµes detalhadas sobre o dataset"""
    print_secao("INFO", "INFORMAÃ‡Ã•ES DO DATASET")

    print(f"ğŸ“ DimensÃµes: {df.shape[0]:,} linhas Ã— {df.shape[1]} colunas")
    print(f"ğŸ’¾ Tamanho em memÃ³ria: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")

    # Tipos de dados
    print(f"\nğŸ“‹ Tipos de dados:")
    tipos = df.dtypes.value_counts()
    for tipo, count in tipos.items():
        print(f"   {tipo}: {count} colunas")

    # Valores ausentes
    missing = df.isnull().sum()
    if missing.sum() > 0:
        print(f"\nâŒ Valores ausentes encontrados:")
        for col, count in missing[missing > 0].items():
            print(f"   {col}: {count:,} ({count/len(df)*100:.1f}%)")
    else:
        print(f"\nâœ… Sem valores ausentes!")

    # EstatÃ­sticas da variÃ¡vel target
    if 'views' in df.columns:
        views = df['views']
        print(f"\nğŸ¯ EstatÃ­sticas da variÃ¡vel target (views):")
        print(f"   ğŸ“Š MÃ©dia: {views.mean():,.0f}")
        print(f"   ğŸ“Š Mediana: {views.median():,.0f}")
        print(f"   ğŸ“Š MÃ­nimo: {views.min():,.0f}")
        print(f"   ğŸ“Š MÃ¡ximo: {views.max():,.0f}")
        print(f"   ğŸ“Š Desvio PadrÃ£o: {views.std():,.0f}")

def calcular_e_exibir_metricas(y_real, y_pred, nome_conjunto, cor_emoji):
    """Calcula e exibe mÃ©tricas de avaliaÃ§Ã£o"""
    rmse = np.sqrt(mean_squared_error(y_real, y_pred))
    mae = mean_absolute_error(y_real, y_pred)
    r2 = r2_score(y_real, y_pred)

    print(f"\n{cor_emoji} {nome_conjunto.upper()}:")
    print(f"   ğŸ“ RMSE (Erro QuadrÃ¡tico MÃ©dio): {rmse:,.0f}")
    print(f"   ğŸ“ MAE (Erro Absoluto MÃ©dio):    {mae:,.0f}")
    print(f"   ğŸ“Š RÂ² (Coeficiente DeterminaÃ§Ã£o): {r2:.4f} ({r2*100:.1f}%)")

    # InterpretaÃ§Ã£o do RÂ²
    if r2 >= 0.9:
        interpretacao = "ğŸŒŸ Excelente!"
    elif r2 >= 0.7:
        interpretacao = "ğŸ‘ Muito bom!"
    elif r2 >= 0.5:
        interpretacao = "ğŸ”§ RazoÃ¡vel"
    else:
        interpretacao = "âŒ Fraco"

    print(f"   ğŸ’¡ InterpretaÃ§Ã£o: {interpretacao}")

    return {'RMSE': rmse, 'MAE': mae, 'R2': r2}

# ===========================================
# CONFIGURAÃ‡ÃƒO INTERATIVA
# ===========================================

print_titulo("ğŸš€ SISTEMA DE MODELAGEM INTERATIVO")
print("Bem-vindo ao sistema de Machine Learning para prediÃ§Ã£o de views do YouTube!")

# Solicitar configuraÃ§Ãµes interativamente
MODELO = solicitar_modelo()

if MODELO == 'Ridge':
    PARAMETROS = solicitar_parametros_ridge()
elif MODELO == 'RandomForest':
    PARAMETROS = solicitar_parametros_randomforest()
elif MODELO == 'GradientBoosting':
    PARAMETROS = solicitar_parametros_gradientboosting()

TAMANHO_TESTE, RANDOM_STATE = solicitar_configuracoes_gerais()

# ===========================================
# CARREGAMENTO DOS DADOS
# ===========================================

print_secao("1", "CARREGAMENTO DOS DADOS")
try:
    df = pd.read_csv('pre_processed_youtube_trending_data.csv')
    print(f"âœ… Arquivo carregado com sucesso!")
    imprimir_info_dataset(df)
except FileNotFoundError:
    print("âŒ ERRO: Arquivo 'pre_processed_youtube_trending_data.csv' nÃ£o encontrado!")
    print("ğŸ’¡ Certifique-se de que o arquivo estÃ¡ no diretÃ³rio atual.")
    exit()

# ===========================================
# PREPARAÃ‡ÃƒO DOS DADOS
# ===========================================

print_secao("2", "PREPARAÃ‡ÃƒO DOS DADOS")

# VariÃ¡vel alvo (o que queremos prever)
y = df['views']

# VariÃ¡veis de entrada (features) - removendo colunas nÃ£o numÃ©ricas
colunas_remover = ['video_id', 'title', 'channel_title', 'publish_time',
                   'tags', 'description', 'thumbnail_link', 'views']
X = df.drop(columns=[col for col in colunas_remover if col in df.columns])

print(f"ğŸ¯ VariÃ¡vel target: 'views' ({len(y):,} valores)")
print(f"ğŸ”¢ Features selecionadas: {X.shape[1]} colunas numÃ©ricas")
print(f"\nğŸ“‹ Lista das features:")
for i, col in enumerate(X.columns, 1):
    print(f"   {i:2d}. {col}")

# Verificar se hÃ¡ valores infinitos ou muito grandes
if np.isinf(X.values).any():
    print("âš ï¸  Valores infinitos detectados - serÃ£o removidos")
    X = X.replace([np.inf, -np.inf], np.nan).dropna()
    y = y.loc[X.index]

print(f"\nâœ… Dados preparados: {X.shape[0]:,} amostras Ã— {X.shape[1]} features")

# ===========================================
# DIVISÃƒO TREINO/TESTE
# ===========================================

print_secao("3", "DIVISÃƒO TREINO/TESTE")

X_treino, X_teste, y_treino, y_teste = train_test_split(
    X, y, test_size=TAMANHO_TESTE, random_state=RANDOM_STATE
)

print(f"ğŸ“Š DivisÃ£o configurada:")
print(f"   ğŸ”µ Treino: {len(X_treino):,} amostras ({(1-TAMANHO_TESTE)*100:.0f}%)")
print(f"   ğŸ”´ Teste:  {len(X_teste):,} amostras ({TAMANHO_TESTE*100:.0f}%)")
print(f"   ğŸ² Random State: {RANDOM_STATE}")

# EstatÃ­sticas dos conjuntos
print(f"\nğŸ“ˆ EstatÃ­sticas da variÃ¡vel target por conjunto:")
print(f"   Treino - MÃ©dia: {y_treino.mean():,.0f} | Desvio: {y_treino.std():,.0f}")
print(f"   Teste  - MÃ©dia: {y_teste.mean():,.0f} | Desvio: {y_teste.std():,.0f}")

# ===========================================
# TREINAMENTO DO MODELO
# ===========================================

print_secao("4", f"TREINAMENTO DO MODELO {MODELO}")

print(f"ğŸ¤– Modelo selecionado: {MODELO}")
print(f"âš™ï¸  ParÃ¢metros configurados:")
for param, valor in PARAMETROS.items():
    print(f"   {param}: {valor}")

# Criando o modelo
if MODELO == 'Ridge':
    modelo = Ridge(**PARAMETROS)
elif MODELO == 'RandomForest':
    modelo = RandomForestRegressor(**PARAMETROS)
elif MODELO == 'GradientBoosting':
    modelo = GradientBoostingRegressor(**PARAMETROS)

print(f"\nğŸš€ Iniciando treinamento...")
modelo.fit(X_treino, y_treino)
print(f"âœ… Modelo {MODELO} treinado com sucesso!")

# ===========================================
# AVALIAÃ‡ÃƒO
# ===========================================

print_secao("5", "AVALIAÃ‡ÃƒO DO MODELO")

# Fazendo previsÃµes
print("ğŸ”® Fazendo previsÃµes...")
y_pred_treino = modelo.predict(X_treino)
y_pred_teste = modelo.predict(X_teste)

# Calculando mÃ©tricas
metricas_treino = calcular_e_exibir_metricas(y_treino, y_pred_treino, "treino", "ğŸ”µ")
metricas_teste = calcular_e_exibir_metricas(y_teste, y_pred_teste, "teste", "ğŸ”´")

# ===========================================
# ANÃLISE DE OVERFITTING
# ===========================================

print_secao("6", "ANÃLISE DE OVERFITTING")

diferenca_r2 = metricas_treino['R2'] - metricas_teste['R2']
diferenca_rmse = abs(metricas_treino['RMSE'] - metricas_teste['RMSE'])

print(f"ğŸ“ˆ ComparaÃ§Ã£o Treino vs Teste:")
print(f"   DiferenÃ§a RÂ²:   {diferenca_r2:+.4f}")
print(f"   DiferenÃ§a RMSE: {diferenca_rmse:,.0f}")

print(f"\nğŸ” DiagnÃ³stico:")
if diferenca_r2 > 0.1 and metricas_treino['R2'] > 0.8:
    print("   âš ï¸  OVERFITTING DETECTADO!")
    print("   ğŸ’¡ O modelo estÃ¡ decorando os dados de treino")
    print("   ğŸ”§ SugestÃµes: aumentar regularizaÃ§Ã£o ou reduzir complexidade")
elif diferenca_r2 > 0.05:
    print("   ğŸŸ¡ Leve overfitting detectado")
    print("   ğŸ’¡ Ainda aceitÃ¡vel, mas monitore")
elif diferenca_r2 < -0.05:
    print("   ğŸŸ  PossÃ­vel underfitting")
    print("   ğŸ’¡ Modelo pode estar muito simples")
else:
    print("   âœ… Modelo bem balanceado!")
    print("   ğŸ’¡ Boa generalizaÃ§Ã£o entre treino e teste")

if metricas_teste['R2'] < 0.3:
    print("   ğŸ“‰ Performance geral baixa no teste")
    print("   ğŸ”§ Considere: mais features, dados ou modelo diferente")

# ===========================================
# SALVANDO RESULTADOS
# ===========================================

print_secao("7", "SALVANDO RESULTADOS")

# Criando estrutura de pastas organizada
pasta_modelo = MODELO  # Pasta principal do modelo (ex: Ridge, RandomForest, GradientBoosting)
nome_execucao = criar_nome_execucao(MODELO, PARAMETROS, TAMANHO_TESTE, RANDOM_STATE)
pasta_execucao = os.path.join(pasta_modelo, nome_execucao)

# Criar pasta do modelo se nÃ£o existir
if not os.path.exists(pasta_modelo):
    os.makedirs(pasta_modelo)
    print(f"ğŸ“ Pasta do modelo criada: {pasta_modelo}/")

# Criar pasta da execuÃ§Ã£o
os.makedirs(pasta_execucao, exist_ok=True)
num_execucoes = contar_execucoes_modelo(pasta_modelo)
print(f"ğŸ“‚ ExecuÃ§Ã£o #{num_execucoes}: {pasta_execucao}/")
print(f"ğŸ’¡ Esta Ã© a {num_execucoes}Âª execuÃ§Ã£o do modelo {MODELO}")

# Salvando mÃ©tricas em CSV
resultados_df = pd.DataFrame({
    'Conjunto': ['Treino', 'Teste'],
    'RMSE': [metricas_treino['RMSE'], metricas_teste['RMSE']],
    'MAE': [metricas_treino['MAE'], metricas_teste['MAE']],
    'R2': [metricas_treino['R2'], metricas_teste['R2']]
})

arquivo_metricas = os.path.join(pasta_execucao, 'metricas_detalhadas.csv')
resultados_df.to_csv(arquivo_metricas, index=False, float_format='%.6f')
print(f"ğŸ’¾ MÃ©tricas salvas: {arquivo_metricas}")

# Salvando configuraÃ§Ãµes usadas
config_dict = {
    'execucao': nome_execucao,
    'modelo': MODELO,
    'parametros': PARAMETROS,
    'tamanho_teste': TAMANHO_TESTE,
    'random_state': RANDOM_STATE,
    'num_amostras_treino': len(X_treino),
    'num_amostras_teste': len(X_teste),
    'num_features': X.shape[1]
}

arquivo_config = os.path.join(pasta_execucao, 'configuracao_utilizada.txt')
with open(arquivo_config, 'w', encoding='utf-8') as f:
    f.write("CONFIGURAÃ‡ÃƒO DO EXPERIMENTO\n")
    f.write("="*50 + "\n\n")
    for chave, valor in config_dict.items():
        f.write(f"{chave}: {valor}\n")

    f.write(f"\nRESULTADOS FINAIS\n")
    f.write("-"*30 + "\n")
    f.write(f"RÂ² no teste: {metricas_teste['R2']:.6f}\n")
    f.write(f"RMSE no teste: {metricas_teste['RMSE']:.2f}\n")
    f.write(f"MAE no teste: {metricas_teste['MAE']:.2f}\n")

print(f"âš™ï¸  ConfiguraÃ§Ãµes salvas: {arquivo_config}")

# GrÃ¡fico de importÃ¢ncia (sÃ³ para RandomForest e GradientBoosting)
if MODELO in ['RandomForest', 'GradientBoosting']:
    print(f"\nğŸŒ² Gerando grÃ¡fico de importÃ¢ncia das features...")
    importancias = pd.Series(modelo.feature_importances_, index=X.columns)
    top_10 = importancias.nlargest(10)

    plt.figure(figsize=(12, 8))
    top_10.plot(kind='barh', color='skyblue', edgecolor='navy')
    plt.title(f'Top 10 - ImportÃ¢ncia das Features\nModelo: {MODELO}', fontsize=14, pad=20)
    plt.xlabel('ImportÃ¢ncia Relativa', fontsize=12)
    plt.ylabel('Features', fontsize=12)
    plt.grid(axis='x', alpha=0.3)
    plt.tight_layout()

    arquivo_grafico = os.path.join(pasta_execucao, 'importancia_features.png')
    plt.savefig(arquivo_grafico, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"ğŸ“Š GrÃ¡fico salvo: {arquivo_grafico}")
elif MODELO == 'Ridge':
    print(f"\nğŸ“ˆ Para Ridge, a importÃ¢ncia estÃ¡ nos coeficientes (nÃ£o hÃ¡ grÃ¡fico automÃ¡tico)")

# ===========================================
# RESUMO FINAL DETALHADO
# ===========================================

print_titulo("ğŸ† RESUMO FINAL DETALHADO")

print(f"ğŸ¤– Modelo: {MODELO}")
print(f"âš™ï¸  ParÃ¢metros:")
for param, valor in PARAMETROS.items():
    print(f"   â€¢ {param}: {valor}")

print(f"\nğŸ“Š Performance no Teste:")
print(f"   â€¢ RÂ²: {metricas_teste['R2']:.4f} ({metricas_teste['R2']*100:.1f}% da variÃ¢ncia explicada)")
print(f"   â€¢ RMSE: {metricas_teste['RMSE']:,.0f} views")
print(f"   â€¢ MAE: {metricas_teste['MAE']:,.0f} views")

print(f"\nğŸ¯ AvaliaÃ§Ã£o Geral:")
if metricas_teste['R2'] >= 0.9:
    print("   ğŸŒŸ EXCELENTE! Modelo muito preciso")
elif metricas_teste['R2'] >= 0.7:
    print("   ğŸ‘ MUITO BOM! Modelo confiÃ¡vel")
elif metricas_teste['R2'] >= 0.5:
    print("   ğŸ”§ RAZOÃVEL. Pode ser melhorado")
else:
    print("   âŒ FRACO. Precisa de melhorias significativas")

print(f"\nğŸ“ Arquivos salvos em: {pasta_execucao}/")
print(f"   â€¢ metricas_detalhadas.csv")
print(f"   â€¢ configuracao_utilizada.txt")
if MODELO in ['RandomForest', 'GradientBoosting']:
    print(f"   â€¢ importancia_features.png")

print(f"\nğŸ“Š Estrutura organizacional:")
print(f"   ğŸ“‚ {pasta_modelo}/ (pasta principal do modelo)")
print(f"   â””â”€â”€ ğŸ“ {nome_execucao}/ (esta execuÃ§Ã£o)")

print("\n" + "="*60)
print("âœ¨ EXECUÃ‡ÃƒO CONCLUÃDA COM SUCESSO! âœ¨")
print("="*60)
